{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikhilSharma2707/Alzheimers-Detection-Using-Deep-Learning-Techniques/blob/master/Random_Forest_Alzheimers_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4OIxmidWC2V",
        "outputId": "94ec2ddd-0661-404a-ac76-e0e64e621aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading imagesoasis, 1322017985 bytes compressed\n",
            "[==================================================] 1322017985 bytes downloaded\n",
            "Downloaded and uncompressed: imagesoasis\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'imagesoasis:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3419493%2F5962731%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240403%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240403T191241Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D70bd965a29bd89e56ac926fa933c80c57716916eefa637fe76d570a3899710a9a1b574e04d0628e996814580c5083adb7e657b787b9b13ba8291b47f4b2448b60b865d8feea05d8031c03bbc8a5bcd4f0f6d90c133ff451fb0148721fe3b18ac42438a4bcb808b4657c5c2cfb86482e61a9e6915e42ccd9559f177ca9fdaaa04f138207204534c2cb70ae7e3c9326821c5aa7a3c180c91e827a14e8a1863daa38f3a4fcdfaf291af8f7f211c0fa78b573ce47fb9c5695c536a974d7327359ef296b253be0e17aabe7cced28a55841d7eed2e2e1aa71d2a21657ab54329ddc3633297edbac51438d5ecfe0cb55fd1e24a68169e24c8046bfd7699ab57fe6a90d3'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import plotly.express as px\n",
        "\n",
        "from keras.models import Sequential\n",
        "from PIL import Image\n",
        "from keras.layers import Conv2D,Flatten,Dense,Dropout,BatchNormalization,MaxPooling2D\n",
        "from sklearn.preprocessing import OneHotEncoder, label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import auc, average_precision_score, confusion_matrix, roc_auc_score, f1_score, confusion_matrix, precision_recall_fscore_support\n",
        "from tensorflow.keras.applications import EfficientNetB0, EfficientNetV2B1\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import clone_model\n",
        "from matplotlib.colors import LogNorm, LinearSegmentedColormap\n",
        "from PIL import Image\n",
        "from scipy.stats import skew\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "Sp7AMV-LYPTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_demented = []\n",
        "very_mild_demented = []\n",
        "mild_demented = []\n",
        "moderate_demented = []\n",
        "\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Non Demented'):\n",
        "    for filename in filenames:\n",
        "        non_demented.append(os.path.join(dirname, filename))\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Very mild Dementia'):\n",
        "    for filename in filenames:\n",
        "        very_mild_demented.append(os.path.join(dirname, filename))\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Mild Dementia'):\n",
        "    for filename in filenames:\n",
        "        mild_demented.append(os.path.join(dirname, filename))\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input/imagesoasis/Data/Moderate Dementia'):\n",
        "    for filename in filenames:\n",
        "        moderate_demented.append(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "M5tG6sYQZT_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(non_demented))\n",
        "print(len(very_mild_demented))\n",
        "print(len(mild_demented))\n",
        "print(len(moderate_demented))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMwzYjVMZld7",
        "outputId": "fe56c75f-705f-4c86-d9b0-041b6ff1610b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67222\n",
            "13725\n",
            "5002\n",
            "488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_info_from_filename(filename):\n",
        "    pattern = re.compile('OAS1_(\\d+)_MR(\\d+)_mpr-(\\d+)_(\\d+).jpg')\n",
        "    match = pattern.match(filename)\n",
        "    patient_id = match.group(1)\n",
        "    mr_id = match.group(2)\n",
        "    scan_id = match.group(3)\n",
        "    layer_id = match.group(4)\n",
        "\n",
        "    return patient_id, mr_id, scan_id, layer_id"
      ],
      "metadata": {
        "id": "fDozxq87Z2H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ref_df(dataset_path):\n",
        "    paths, labels = [], []\n",
        "    patient_ids, mr_ids, scan_ids, layer_ids = [], [], [], []\n",
        "\n",
        "\n",
        "    for folder in os.listdir(dataset_path):\n",
        "\n",
        "\n",
        "        for file in os.listdir(os.path.join(dataset_path, folder)):\n",
        "\n",
        "\n",
        "            patient_id, mr_id, scan_id, layer_id = get_info_from_filename(file)\n",
        "\n",
        "            # Append information to respective lists\n",
        "            paths.append(os.path.join(dataset_path, folder, file))\n",
        "            labels.append(folder)\n",
        "            patient_ids.append(patient_id)\n",
        "            mr_ids.append(mr_id)\n",
        "            scan_ids.append(scan_id)\n",
        "            layer_ids.append(layer_id)\n",
        "\n",
        "    # Create a DataFrame from the collected information\n",
        "    ref_df = pd.DataFrame({\n",
        "        'path': paths,\n",
        "        'label': labels,\n",
        "        'patient_id': patient_ids,\n",
        "        'mr_id': mr_ids,\n",
        "        'scan_id': scan_ids,\n",
        "        'layer_id': layer_ids\n",
        "    })\n",
        "\n",
        "    # Convert columns to appropriate data types\n",
        "    ref_df = ref_df.astype({\n",
        "        'path': 'string',\n",
        "        'label': 'string',\n",
        "        'patient_id': 'int64',\n",
        "        'mr_id': 'int64',\n",
        "        'scan_id': 'int64',\n",
        "        'layer_id': 'int64'\n",
        "    })\n",
        "\n",
        "    return ref_df"
      ],
      "metadata": {
        "id": "xhmA_y2caO_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_df = create_ref_df('/kaggle/input/imagesoasis/Data')"
      ],
      "metadata": {
        "id": "Oo3NmBwmaZrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels_and_paths(ref_df):\n",
        "    labels = []\n",
        "    paths = []\n",
        "\n",
        "    # Iterate through rows of the reference DataFrame\n",
        "    for idx, row in tqdm(ref_df.iterrows(), total=ref_df.shape[0]):\n",
        "\n",
        "        # Append label and path to respective lists\n",
        "        labels.append(row['label'])\n",
        "        paths.append(row['path'])\n",
        "\n",
        "    # Return lists of labels and paths\n",
        "    return labels, paths\n"
      ],
      "metadata": {
        "id": "swSLdJSAayKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, paths = load_labels_and_paths(ref_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x1PEnrGa0pJ",
        "outputId": "1fc8b35b-d7c4-4c08-e4dd-973da9032573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 86437/86437 [00:04<00:00, 18302.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_stats(images, labels, paths):\n",
        "    means, stds, widths, heights = [], [], [], []\n",
        "    skewnesses = []\n",
        "\n",
        "    # Iterate through the images\n",
        "    for image in tqdm(images):\n",
        "\n",
        "        # Calculate mean and standard deviation\n",
        "        means.append(np.mean(image))\n",
        "        stds.append(np.std(image))\n",
        "\n",
        "        # Get image width and height\n",
        "        widths.append(image.shape[0])\n",
        "        heights.append(image.shape[1])\n",
        "\n",
        "        # Calculate skewness of the image histogram\n",
        "        image_hist = np.histogram(image.flatten())[0]\n",
        "        skewnesses.append(skew(image_hist))\n",
        "\n",
        "    # Create a DataFrame with image statistics\n",
        "    image_stats = pd.DataFrame({\n",
        "        'mean': means,\n",
        "        'std': stds,\n",
        "        'width': widths,\n",
        "        'height': heights,\n",
        "        'skew': skewnesses\n",
        "    })\n",
        "\n",
        "    # Add labels and paths to the DataFrame\n",
        "    image_stats['label'] = labels\n",
        "    image_stats['path'] = paths\n",
        "\n",
        "    return image_stats"
      ],
      "metadata": {
        "id": "SleRibCMb6mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequencies = [len(non_demented),  len(very_mild_demented), len(moderate_demented), len(mild_demented),]\n",
        "class_names = [\"non_demented\", \"very_mild_demented\", \"moderate_demented\", \"mild_demented\"]\n",
        "\n",
        "# Sorting class_names and frequencies in descending order\n",
        "sorted_indices = np.argsort(frequencies)[::-1]\n",
        "class_names = np.array(class_names)[sorted_indices]\n",
        "frequencies = np.array(frequencies)[sorted_indices]"
      ],
      "metadata": {
        "id": "5yNqtRBsc6io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "\n",
        "# To split the test set for morderate_demented\n",
        "moderate_demented_train, moderate_demented_test = train_test_split(\n",
        "    moderate_demented, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# To split the test set for mild_demented\n",
        "mild_demented_train, mild_demented_test = train_test_split(\n",
        "    mild_demented, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# To split the test set for very_mild_demented\n",
        "very_mild_demented_train, very_mild_demented_test = train_test_split(\n",
        "    very_mild_demented, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# To split the test set for non_demented\n",
        "non_demented_train, non_demented_test = train_test_split(\n",
        "    non_demented, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "IFUh9YS5fFOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(non_demented_train))\n",
        "print(len(very_mild_demented_train))\n",
        "print(len(mild_demented_train))\n",
        "print(len(moderate_demented_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czwiZZ8tfgR-",
        "outputId": "bffdd945-64fa-4c20-ea24-7ae4f53d4b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53777\n",
            "10980\n",
            "4001\n",
            "390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_samples = 5000\n",
        "\n",
        "\n",
        "moderate_demented_samp = random.choices(moderate_demented_train, k=target_samples)\n",
        "mild_demented_samp = random.choices(mild_demented_train, k=target_samples)\n",
        "\n",
        "\n",
        "very_mild_demented_samp = random.sample(very_mild_demented_train, k=target_samples)\n",
        "non_demented_samp = random.sample(non_demented_train, k=target_samples)"
      ],
      "metadata": {
        "id": "Ix_kv0nNfl_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(non_demented_samp))\n",
        "print(len(very_mild_demented_samp))\n",
        "print(len(mild_demented_samp))\n",
        "print(len(moderate_demented_samp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HyA3oqmfztp",
        "outputId": "0b77118f-382f-4456-e731-387a166c1369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n",
            "5000\n",
            "5000\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(non_demented_test))\n",
        "print(len(very_mild_demented_test))\n",
        "print(len(mild_demented_test))\n",
        "print(len(moderate_demented_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd0WM6q8f5e3",
        "outputId": "e7854977-8bc3-49aa-b14f-e5a668782a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13445\n",
            "2745\n",
            "1001\n",
            "98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_samples = 640\n",
        "\n",
        "# Undersample large classes\n",
        "mild_demented_test = random.sample(mild_demented_test, k=target_samples)\n",
        "very_mild_demented_test = random.sample(very_mild_demented_test, k=target_samples)\n",
        "non_demented_test = random.sample(non_demented_test, k=target_samples)"
      ],
      "metadata": {
        "id": "HMdg8DylgLYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(non_demented_test))\n",
        "print(len(very_mild_demented_test))\n",
        "print(len(mild_demented_test))\n",
        "print(len(moderate_demented_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K6XwOZ2gPIR",
        "outputId": "cad24365-485f-4cba-c2be-3335f3e27b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "640\n",
            "640\n",
            "640\n",
            "98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder()\n",
        "encoder.fit([[0],[1],[2],[3]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "aG72OtdEgTGU",
        "outputId": "c8191608-ab64-4d26-c44f-61c16ff76938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneHotEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty objects to store the data and the class labels (result) in\n",
        "data = []\n",
        "result = []\n",
        "\n",
        "# Loop through each category and transform data and result into right format (128x128x3 & one-hot encoded)\n",
        "for path in non_demented_samp:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[0]]).toarray())\n",
        "\n",
        "for path in very_mild_demented_samp:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[1]]).toarray())\n",
        "\n",
        "for path in mild_demented_samp:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[2]]).toarray())\n",
        "\n",
        "for path in moderate_demented_samp:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[3]]).toarray())"
      ],
      "metadata": {
        "id": "5o1qjqbBgah8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform data to numpy array\n",
        "data = np.array(data)\n",
        "\n",
        "# Check shape\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAXGJLJkhQ00",
        "outputId": "747daec7-c71c-40f4-a0d3-340000eb1dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(result)\n",
        "\n",
        "# Reshape to the one-hot encoded format\n",
        "result = result.reshape((data.shape[0],4))\n",
        "\n",
        "# Check shape\n",
        "result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MCHLmvhj-4j",
        "outputId": "642fd7c2-f9bc-42bc-e0b7-b33a9e990080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(data,result, test_size=0.20, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "l3Pn6FdckBm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = []\n",
        "result_test = []\n",
        "\n",
        "for path in non_demented_test:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data_test.append(np.array(img))\n",
        "        result_test.append(encoder.transform([[0]]).toarray())\n",
        "\n",
        "for path in very_mild_demented_test:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data_test.append(np.array(img))\n",
        "        result_test.append(encoder.transform([[1]]).toarray())\n",
        "\n",
        "for path in mild_demented_test:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data_test.append(np.array(img))\n",
        "        result_test.append(encoder.transform([[2]]).toarray())\n",
        "\n",
        "for path in moderate_demented_test:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((128,128))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (128,128,3)):\n",
        "        data_test.append(np.array(img))\n",
        "        result_test.append(encoder.transform([[3]]).toarray())\n"
      ],
      "metadata": {
        "id": "6yQNFg72kEj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = np.array(data_test)\n",
        "data_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZQXomMekRsG",
        "outputId": "e77d0eaa-9b07-4e4f-c85e-e47ebdb62128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2018, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_test = np.array(result_test)\n",
        "result_test = result_test.reshape((data_test.shape[0],4))\n",
        "result_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evV8FR_LkWBW",
        "outputId": "b963ee2c-276c-4d08-82ec-3be8a89e2f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2018, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_int = np.argmax(y_train, axis=1)\n",
        "y_val_int = np.argmax(y_val, axis=1)"
      ],
      "metadata": {
        "id": "KeP-j-_Ak5fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = data_test\n",
        "y_test = result_test"
      ],
      "metadata": {
        "id": "8qwX88-ykYqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# Flatten the images into 1D arrays (example)\n",
        "X_train_flat = x_train.reshape((x_train.shape[0], -1))\n",
        "X_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
        "\n",
        "# Initialize and train the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train_flat, y_train_int)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf_classifier.predict(X_test_flat)\n",
        "\n",
        "# Calculate metrics\n",
        "# Convert one-hot encoded labels to single integer labels for test set\n",
        "y_test_int = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf_classifier.predict(X_test_flat)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_rf = accuracy_score(y_test_int, y_pred_rf)\n",
        "f1_rf = f1_score(y_test_int, y_pred_rf, average='weighted')\n",
        "precision_rf = precision_score(y_test_int, y_pred_rf, average='weighted')\n",
        "recall_rf = recall_score(y_test_int, y_pred_rf, average='weighted')\n",
        "conf_matrix_rf = confusion_matrix(y_test_int, y_pred_rf)\n",
        "\n",
        "\n",
        "# Print metrics\n",
        "print(f'Random Forest Accuracy: {accuracy_rf}')\n",
        "print(f'Random Forest F1 Score: {f1_rf}')\n",
        "print(f'Random Forest Precision: {precision_rf}')\n",
        "print(f'Random Forest Recall: {recall_rf}')\n",
        "print(\"Random Forest Confusion Matrix:\")\n",
        "print(conf_matrix_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuIMaX4ansoN",
        "outputId": "66035199-be54-4274-d114-ae2277e43dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9866204162537165\n",
            "Random Forest F1 Score: 0.9866118023657907\n",
            "Random Forest Precision: 0.9867225558710347\n",
            "Random Forest Recall: 0.9866204162537165\n",
            "Random Forest Confusion Matrix:\n",
            "[[620  19   1   0]\n",
            " [  7 633   0   0]\n",
            " [  0   0 640   0]\n",
            " [  0   0   0  98]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump\n",
        "\n",
        "# Save the model\n",
        "dump(rf_classifier, \"Random_Forest_Alzheimers_V1.joblib\")\n"
      ],
      "metadata": {
        "id": "YFM8xtyrpy8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23134f07-cc7a-4f12-f867-98b9923a11b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Random_Forest_Alzheimers_V1.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import load\n",
        "\n",
        "# Load the model\n",
        "loaded_rf_model = load(\"/content/Random_Forest_Alzheimers_V1.joblib\")\n"
      ],
      "metadata": {
        "id": "_6fyDV0JqTbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}